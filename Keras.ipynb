{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "num_classes = 12\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "# the data, split between train and test sets\n",
    "\n",
    "##### import image dataset #####\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cate_label=[]\n",
    "DATASET_LOCATION = './gear_images_new'\n",
    "imglabel_db = defaultdict(list)\n",
    "for imgclass in os.listdir(DATASET_LOCATION):\n",
    "    imgclass_path = DATASET_LOCATION + \"/\" + imgclass\n",
    "    imgclass_arr = []\n",
    "    cate_label.append(imgclass)\n",
    "    for filename in os.listdir(imgclass_path):\n",
    "        \n",
    "        img_path = imgclass_path + \"/\" + filename\n",
    "\n",
    "        #print(img_path)\n",
    "        #imgcount += 1\n",
    "        img = Image.open(img_path)\n",
    "        #convert images to RGB arrays\n",
    "        img_arr = np.array(img)\n",
    "        imgclass_arr.append(img_arr) #no need to flatten, retaint the shape\n",
    "        img.close()\n",
    "\n",
    "    imglabel_db[imgclass]=imgclass_arr\n",
    "    \n",
    "    \n",
    "def datasplit(database, testSize):\n",
    "    #divide image data (X) and labels (y)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "   \n",
    "    for label in database:\n",
    "        for imgdata in database[label]:\n",
    "            X.append(imgdata)\n",
    "            y.append(label)\n",
    "            \n",
    "\n",
    "    #split X and y into train and test\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state =42)\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1697, 128, 128, 3)\n",
      "1697 train samples\n",
      "1697 test samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(cate_label)\n",
    "X_train, y_train, X_test, y_test = datasplit(imglabel_db, 0.2)\n",
    "y_test=le.transform(y_test)\n",
    "y_train=le.transform(y_train)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_train.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices - this is for use in the\n",
    "# categorical_crossentropy loss below\n",
    "# binary_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1697 samples, validate on 425 samples\n",
      "Epoch 1/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 1.3891 - acc: 0.6070 - val_loss: 9.7493 - val_acc: 0.1741\n",
      "Epoch 2/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.4570 - acc: 0.8533 - val_loss: 1.7491 - val_acc: 0.4941\n",
      "Epoch 3/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.2590 - acc: 0.9169 - val_loss: 0.3638 - val_acc: 0.8800\n",
      "Epoch 4/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.1566 - acc: 0.9452 - val_loss: 1.5153 - val_acc: 0.7412\n",
      "Epoch 5/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.1215 - acc: 0.9658 - val_loss: 0.6161 - val_acc: 0.8612\n",
      "Epoch 6/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.0841 - acc: 0.9758 - val_loss: 0.4476 - val_acc: 0.9200\n",
      "Epoch 7/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.0896 - acc: 0.9806 - val_loss: 0.4559 - val_acc: 0.9200\n",
      "Epoch 8/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.0354 - acc: 0.9912 - val_loss: 0.7018 - val_acc: 0.8918\n",
      "Epoch 9/12\n",
      "1697/1697 [==============================] - 33s 20ms/step - loss: 0.0456 - acc: 0.9912 - val_loss: 0.5190 - val_acc: 0.9200\n",
      "Epoch 10/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.0296 - acc: 0.9923 - val_loss: 0.4740 - val_acc: 0.9176\n",
      "Epoch 11/12\n",
      "1697/1697 [==============================] - 33s 20ms/step - loss: 0.0247 - acc: 0.9882 - val_loss: 0.6936 - val_acc: 0.8753\n",
      "Epoch 12/12\n",
      "1697/1697 [==============================] - 34s 20ms/step - loss: 0.0195 - acc: 0.9959 - val_loss: 0.5328 - val_acc: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6b6f333400>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape= (128,128,3)\n",
    "\n",
    "### build model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "## change parameters and layer\n",
    "model.add(Conv2D(20, (5, 5), padding='valid', activation='relu', input_shape=input_shape, data_format=\"channels_last\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(50, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(12))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5327616834289888\n",
      "Test accuracy: 0.927058823669658\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
